# 计算机硬件

计算机的重要组成部分，包含了 5 个重要的组成部分：**运算器、控制器、存储器、输入设备、输出设备**。

- `运算器`：运算器最主要的功能是对数据和信息进行加工和运算。它是计算机中执行算数和各种逻辑运算的部件。运算器的基本运算包括加、减、乘、除、移位等操作，这些是由 `算术逻辑单元(ALU)` 实现的。而运算器主要由算数逻辑单元和寄存器构成。
- `控制器`：指按照指定顺序改变主电路或控制电路的部件，它主要起到了控制命令执行的作用，完成协调和指挥整个计算机系统的操作。控制器是由程序计数器、指令寄存器、解码译码器等构成。

> 运算器和控制器共同组成了 CPU

- `存储器`：存储器就是计算机的`记忆设备`，可以保存信息。存储器分为两种，一种是主存，也就是内存，它是 CPU 主要交互对象，还有一种是外存，比如硬盘软盘等。
- `输入设备`：输入设备是给计算机获取外部信息的设备，它主要包括键盘和鼠标。
- `输出设备`：输出设备是给用户呈现根据输入设备获取的信息经过一系列的计算后得到显示的设备，它主要包括显示器、打印机等。
- `I/O 设备`：Input/Output 设备是系统和外部世界的连接。
- `总线`：**贯穿整个系统的一组电子管道**，通常被设计成用来传送定长的字节块，也就是字。**字的大小与系统相关，比如在32位操作系统当中，一个字是4个字节**。
- `主存`：主存是一个`临时存储设备`，而不是永久性存储，磁盘是 `永久性存储` 的设备。主存既保存程序，又保存处理器执行流程所处理的数据。从物理组成上说，主存是由一系列动态随机存储构成的集合。
- `CPU`：由**用于保存变量和临时结果的寄存器、程序计数器（下一条要执行的指令地址）、堆栈指针、PSW程序状态字寄存器（IO和系统调用常用到）**等寄存器组成。CPU 在指令的要求下会做如下操作：
     1. 加载：把一个字节或者一个字从主存复制到寄存器，以覆盖寄存器原来的内容
     2. 存储：把一个字节或者一个字从寄存器复制到主存的某个位置，以覆盖这个位置上原来的内容
     3. 操作：把两个寄存器的内容复制到 ALU，ALU 对这两个字做算术操作，并把结果存放到一个寄存器中，以覆盖寄存器原来的内容
     4. 跳转：从指令本身中抽取一个字，并将这个字复制到程序计数器（PC）中，以覆盖PC中原来的内容。

![202109102226499633.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102226499633.png)

# 计算机概念

计算机是由软件与硬件组成的，而硬件又包括了总线、I/O设备、主存以及处理器，其中**信息是由位以及上下文**表示的，而信息则是从I/O设备以位的形式通过总线进入主存，然后由处理器从主存将信息取出处理。

- **位**："位(bit)"是电子计算机中最小的数据单位。每一位的状态只能是0或1。
- **字节**：8个二进制位构成1个"字节(Byte)"，它是存储空间的基本计量单位。1个字节可以储存1个英文字母或者半个汉字。
- **字**："字"由若干个字节构成，字的位数叫做字长，不同档次的机器有不同的字长。
- **ASCII**：美国信息交换标准代码。注意不是ASCⅡ(罗马数字2)，使用指定的7位或8 位二进制数组合来表示128或256种可能的字符。

## 字与字长

**指令集结构描述的是每条机器代码指令的效果，而微体系结构描述的是处理器实际上是如何实现的**。

计算机一次处理的数据长度称为**字**，一个字通常由一个或多个字节构成，**字的位数叫做字长**。由于虚拟地址空间中的地址就是使用一个字来编码的，因此字长决定了系统的虚拟地址空间的最大大小。**字长指的是CPU一次能并行处理的二进制位数。**

对于跨越多个字节的程序对象来说，有两个问题：

- 这个对象的地址是什么？
- 在存储器中如何排列这些字节？

对象的地址：**在几乎所有的机器上，多字节对象都被存储为连续的字节序列，对象的地址为所使用字节中最小的地址。**

排列方式：

- **小端法**：按照从最低有效字节到最高有效字节的顺序存储对象，也就是最低有效字节在最前面。
- **大端法**：和小端法相反。是按照从最高有效字节到最低有效字节的顺序存储对象，也就是最高有效字节在最前面。

## 程序的运行

**程序的编译**：

预处理器、编译器、汇编器和链接器一起构成了编译系统。

![202109102140332872.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102140332872.png)

- **预处理阶段**：预处理器 cpp 根据以字符 # 开头的命令，修改原始的 C 程序，处理头文件使得引用代码插入源代码中，得到以 .i 作为文件扩展名的源程序。
- **编译阶段**：编译器 ccl 将文本文件 hello.i 翻译成文本文件 hello.s，它包含一个汇编语言程序，汇编语言程序中的每条语句都以一种标准的文本格式确切的描述一条低级机器语言指令。汇编语言能为不同高级语言的不同编译器提供通用的输出语言。
- **汇编阶段**：汇编器 as 将hello.s 翻译成机器语言指令，把这些指令打包成一种叫做可重定位目标程序的格式，并将结果保存在**字节编码为机器码**的hello.o 中。
- **链接阶段**：链接器 ld 就是负责处理相关调用，将相关调用的机器码合并到源文件中，结果就得到一个 hello 文件，它是一个可执行目标程序，可以被加载到内存中，由系统运行。

**计算机组成预览**：

![202109102140344455.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102140344455.png)

一个程序的执行，是经历了预处理器、编译器、汇编器以及链接器的处理之后，才最终成为可执行的文件。

# 操作系统概念

## 概念

**操作系统是管理硬件和软件的一种应用程序。**是管理计算机硬件与软件资源的系统`软件`，同时也是计算机系统的`内核与基石`。计算机有两种运行模式：**内核态（管态和核心态）和用户态**。操作系统提供了几种抽象模型:

- 文件：对 I/O 设备的抽象
- 虚拟内存：对程序存储器的抽象
- 进程：对一个正在运行程序的抽象
- 虚拟机：对整个操作系统的抽象

![202109102232368931.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102232368931.png)

## **主要功能**

- **处理器管理**：进行相关的任务调度，解决处理其调度、分配、回收等。
- **存储器管理**：负责管理内存的分配、回收，在进程需要时分配内存以及完成时回收内存，协调内存资源。
- **设备管理**：根据确定的设备分配原则对设备进行分配，使设备与主机能够并行工作。
- **文件管理**：有效地管理文件的存储空间，合理地组织和管理文件系统，为文件访问和文件保护提供更有效的方法及手段。
- **提供用户接口**：提供了访问应用程序和硬件的接口，方便用户使用。

## 操作系统特性

操作系统还具有四个重要特性：并发性、共享性、虚拟性、异步性。

**并发性**

- 并行是指两个或多个事件可以在**同一时刻**发生
- 并发是指两个或多个事件可以在同一**时间间隔刻**发生

**共享性**

- 共享性表现为操作系统中的资源**可供多个并发的程序共同使用**
  - 互斥共享：资源互斥访问
  - 同时访问：某一个资源在一段时间内**并发**地被多个程序访问，这种“同时”是**宏观的**

**虚拟性**

虚拟性表现为把一个**物理实体**转变为若干个**逻辑实体**。

- 时空复用技术：在时间上复用，程序并发使用。

  - **虚拟处理器技术**：

    - 借助多道程序的技术
    - 为每道程序建立进程

    - 多个程序分时复用处理器

  - **虚拟设备技术**：

    - 物理设备虚拟为多个逻辑设备
    - 每个程序占用一个逻辑设备

    - 多个程序通过逻辑设备并发访问

- 空分复用技术：实现虚拟磁盘、虚拟内存，提高资源利用率和编程效率。

  - **虚拟磁盘技术**：
    - 将物理磁盘虚拟为多个**逻辑磁盘**
  - **虚拟内存技术**：
    - 在逻辑上扩大了程序的存储容量，程序可以使用比实际内存大的空间（暂不需要的程序部分挂起在磁盘）

**异步性**

进程是以不可预知的速度向前推进的，不知道程序何时执行、何时暂停、何时完成，这么多的不可预知的事情，就导致了程序的异步性。

## 局部性原理

**局部性原理指的是CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中**。这个原理也是使得虚拟内存技术可以实现的一个原因

因为有局部性原理

- 所以计算机在加载程序时，无需全部逻辑空间装入内存，装载部分即可(需要使用的部分)
- 如果发现所使用的内存不在物理内存中，则发出**缺页中断**，发起页面置换，把保存在辅存中的页面置换到物理内存中，这样程序又可以继续运行下去了

- 从用户层面看，程序拥有很大的空间，既是**虚拟内存**

**虚拟内存实际上是对物理内存的扩充，速度接近于内存，成本接近于辅存**

# 进程

## 进程的组成

**进程是操作系统中分配资源的最小单位**。进程由 3 个部分组成，分别是**程序代码**、**数据集、栈**和**进程控制块（PCB）**。

各自的作用如下：

1. **程序代码**：描述了进程需要完成的功能。

2. **数据集、栈**：程序在执行时所需要的数据和工作区。

3. **进程控制块**：包含进程的描述信息和控制信息，它是进程存在的唯一标识。

4. **PCB**：用来描述和控制进程运行的**通用数据结构**，是进程能够独立运行的基本单位。（常驻内存，存在系统专门开放的PCB块）

   <img src="https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/1609489163170-9f7444e4-51a7-4f04-a7f2-027d2dfab847.png" alt="1609489163170-9f7444e4-51a7-4f04-a7f2-027d2dfab847" style="zoom:33%;" />

## **进程的状态**

![2021091022324624415.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/2021091022324624415.png)

1. 创建态，分配PCB块，插入就绪队列，还未申请其他资源
2. 就绪态，拥有除了CPU以外的资源
3. 运行态，进程获得CPU执行权，正在执行
4. 阻塞态，由于某种原因，位于阻塞状态，放弃CPU
5. 终止态，进程结束后由系统清理并归还PCB块

## 进程通信

   并发进程之间的交互必须满足两个基本要求：同步和通信。

![2021091022270021321.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/2021091022270021321.png)

**信号signal**：通过向一个或多个进程发送`异步事件信号`来实现，如：SIGSTOP、SIGKILL等信号。

**管道pipe**：在两个进程之间，可以建立一个通道，一个进程向通道写入字节流，另一个进程从管道读取字节流。管道是同步的，当进程尝试从空管道读取数据时，该进程会被阻塞，直到有可用数据为止。**如linux的 | 管线**

**共享内存**：通过共享内存进行进程间通信，一个进程所作的修改对另一个进程可见。

**先入先出队列FIFO**：也称**命名管道**，具有支持文件和独特 API ，命名管道在文件系统中作为设备的专用文件存在。而非命名管道在结束后缓冲区会被系统回收。

**消息队列**：描述内核寻址空间内的内部链接列表。可以按几种不同的方式将消息按顺序发送到队列并从队列中检索消息。每个消息队列由 IPC 标识符唯一标识。

**套接字Socket**：提供端到端的双向通信，可有TCP、UDP的支持。

## 进程同步

**临界资源**：指的是一些虽作为**共享资源**却又无法同时被多个进程或线程共同访问的共享资源。为了对临界资源进行有效的约束，就提出了**进程间同步的四个原则**

- 空闲让进：资源无占用，允许使用
- 忙则等待：资源被占用，请求进程等待
- 有限等待：保证有限等待时间能够使用资源，避免其它等待的进程僵死
- 让权等待：等待时，进程需让出CPU，也就是进程由执行状态变为阻塞状态，这也是保证CPU可以高效使用的前提

把进程中访问临界资源的那段代码称为临界区。

![202109102216207762.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102216207762.png)

**竞态条件：**两个或多个线程同时对一共享数据进行修改，从而影响程序运行的正确性时，这种就被称为竞态条件(race condition)。

![202109102216204721.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102216204721.png)

**忙等互斥**

- **屏蔽中断**
  - 进程在进入临界区后立即`屏蔽所有中断`，并在离开临界区之前重新启用它们。屏蔽中断后，时钟中断也会被屏蔽。CPU 只有发生时钟中断或其他中断时才会进行进程切换。这样，在屏蔽中断后 CPU 不会切换到其他进程。所以，一旦某个进程屏蔽中断之后，它就可以检查和修改共享内存，而不用担心其他进程介入访问共享数据。

- **锁变量**
  - 线程想要进入关键区域时，先查看锁的值是否为 0 ，若锁的值是 0 ，进程会把它设置为 1 并让进程进入关键区域。如果锁的状态是 1，进程会等待直到锁变量的值变为 0 。

![202109102216213153.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102216213153.png)

- **严格轮询法**
  - 连续检查一个变量直到某个值出现为止，这种方法称为 `忙等待(busywaiting)`。只有认为等待时间是非常短的情况下，才能够使用忙等待。用于忙等待的锁，称为 `自旋锁(spinlock)`。

- **Peterson解法**
  - 在使用共享变量时（即进入其临界区）之前，各个进程使用各自的进程号 0 或 1 作为参数来调用 `enter_region`，函数调用在需要时将使进程等待，直到安全的临界区。在完成对共享变量的操作之后，进程将调用 `leave_region` 表示操作完成，并且允许其他进程进入

### 死锁

死锁定义：**如果一组进程中的每个进程都在等待一个事件，而这个事件只能由该组中的另一个进程触发，这种情况会导致死锁**。

**死锁的条件**：

1. 互斥条件：资源是排他性使用的
2. 保持和等待条件：已拥有资源的进程不释放自己的资源，去申请新的资源
3. 不可抢占条件：进程未使用完的资源不能被其他进程剥夺
4. 循环等待：死锁发生时，必存在资源环形链路

**处理死锁策略**：

1. 鸵鸟算法（忽略死锁带来的影响）
2. 检测死锁并恢复死锁，死锁发生时对其进行检测，一旦发生死锁后，采取行动解决问题（分配时监测是否会发生死锁，可以通过回滚、抢占、杀死进程恢复死锁）
3. 通过合理分配资源来避免死锁（银行家算法，根据空闲资源表和资源需求表合理分配资源）
4. 通过破坏死锁产生的四个条件之一来避免死锁
   - 破坏互斥条件
   - 破坏保持等待条件
   - 破坏不可抢占条件
   - 破坏循环等待条件

### 两阶段加锁

一种解决方式是使用 `两阶段提交(two-phase locking)`。顾名思义分为两个阶段，一阶段是进程尝试一次锁定它需要的所有记录。如果成功后，才会开始第二阶段，第二阶段是执行更新并释放锁。第一阶段并不做真正有意义的工作。

如果在第一阶段某个进程所需要的记录已经被加锁，那么该进程会释放所有锁定的记录并重新开始第一阶段。从某种意义上来说，这种方法类似于预先请求所有必需的资源或者是在进行一些不可逆的操作之前请求所有的资源。

### 通信死锁

进程 A 给进程 B 发了一条消息，然后进程 A 阻塞直到进程 B 返回响应。假设请求消息丢失了，那么进程 A 在一直等着回复，进程 B 也会阻塞等待请求消息到来，这时候就产生`死锁`。

解决方法：超时重传

![20171121130628916](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/20171121130628916.png)

### 临界区

通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。

优点：保证在某一时刻只有一个线程能访问数据的简便办法

缺点：虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用来同步多个进程中的线程。

 ### 互斥量

为协调共同对一个共享资源的单独访问而设计的。互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限。

优点：实现在同一应用程序不同线程中资源的安全共享，且实现在不同应用程序的线程之间对资源的安全共享。

缺点：

- 互斥量是可以命名的，也就是说它可以跨越进程使用，所以创建互斥量需要的资源更多。

- 通过互斥量可以指定资源被独占的方式使用，并发度不好。

 ### 信号量

为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。

优点：适用于对Socket（套接字）程序中线程的同步。

缺点：

- 信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点；
- 信号量机制功能强大，但使用时对信号量的操作分散， 而且难以控制，读写和维护都很困难，加重了程序员的编码负担；
- 核心操作P-V分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严重，且不易发现和纠正。

 ### 事件

用来通知线程有一些事件已发生，从而启动后继任务的开始。

优点：事件对象通过通知操作的方式来保持线程的同步，并且可以实现不同进程中的线程同步操作。

### 管程

管程是程序、变量和数据结构等组成的一个集合，它们组成一个特殊的模块或者包。进程可以在任何需要的时候调用管程中的程序，但是它们不能从管程外部访问数据结构和程序。

### 总结

①临界区不是内核对象，只能用于进程内部的线程同步，是用户方式的同步。互斥、信号量是内核对象可以用于不同进程之间的线程同步（跨进程同步）。

②互斥其实是信号量的一种特殊形式。互斥可以保证在某一时刻只有一个线程可以拥有临界资源。信号量可以保证在某一时刻有指定数目的线程可以拥有临界资源。

## fork进程

- fork系统调用是用于**创建进程**的
- 对于虚拟空间地址来说，子进程会拷贝父进程的虚拟地址空间。所以，**fork后子进程的用户区与父进程的用户区相同**，也会**拷贝内核区内容**，仅仅是**进程的 pid**不同。

- 在父进程中返回子进程的ID，在子进程中返回0。所以可以通过`fork` 的返回值来区分父进程与子进程
- fork系统调用**无参数**

运用了**读时共享、写时拷贝**的原则，fork后，**父子进程共享父进程的地址空间**（只读），在父进程或者子进程进行写指令时，子进程才会复制一份地址空间，从而使得虚拟地址空间独立，在自己的地址空间进行**写操作**。也就是说，**资源的复制是在需要写入时才会进行，在此之前，只会以只读方式进行共享**。

## 进程类型

前台进程：具有终端，可以和用户进行交互的进程

后台进程：不与用户进行交互，优先级比前台进程低

守护进程：特殊的后台进程

孤儿进程：父进程退出后，子进程即成为孤儿进程，将由**init进程（pid为1）**收养

僵尸进程：子进程的进程描述符在子进程退出后不会释放，只有当父进程调用**wait()、waitpid()**获取子进程信息才释放

# 线程

**线程是操作系统进行运行调度的最小单位**，线程除了拥有自己的栈、程序计数器等资源外，共享进程的资源。

**通信**，对于进程来说是进程间的通信(**IPC**)，而对于线程，它是通过读写同一个进程的数据进行通信。



## 线程同步

**互斥量**

- 本质上是资源排他性使用，效果相当于**原子性**。拥有两种状态：**加锁和解锁**。（会带来相关损耗，**阻塞锁**）
  - **自旋锁**：等待获取资源的时候CPU不会释放，**优点**：如果线程占用锁时间不长，就能避免上下文切换代价；**缺点**：耗费CPU时间
  - **读写锁**：读不进行加锁，写的时候进行加锁，对于多读少写的情况，性能能有很好的提升

**信号量**：表示同时允许访问资源的最大线程数量，它是一个全局变量。（Java的semaphore）

**事件**：利用线程间共享的全局变量进行同步的一种机制，主要包括两个动作：一个线程等待某个条件为真，而将自己挂起；另一个线程设置条件为真，并通知等待的线程继续。**条件变量与互斥量一起使用时，允许线程以无竞争的方式等待特定的条件发生。**

- 基本动作：wait、signal、notify

**临界区**

通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。

## 调度算法

- 调度算法的目标：
- ![202109102216334083.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102216334083.png)

- **先来先服务**：按照FIFO的原则，将作业加入到就绪队列中，按照顺序调度作业。
- **最短作业优先**：按照线程作业的CPU时间片，优先调度所需最短CPU时间片的作业。
- **最短剩余时间**：最短作业优先的抢占式版本，总是调度剩余运行时间最短的作业。
- **轮询调度**：每个作业都会被分配一个CPU时间片，在这个时间片内允许进程运行。如果时间片结束时进程还在运行的话，则抢占一个 CPU 并将其分配给另一个进程。
- **优先级调度**：按照作业优先级进行调度。
- **多级反馈队列**：设置多级队列，设置不同优先级，并且分配不同的时间片。

## POSIX线程

即线程标准。

| 线程调用             | 描述                           |
| -------------------- | ------------------------------ |
| pthread_create       | 创建一个新线程                 |
| pthread_exit         | 结束调用的线程                 |
| pthread_join         | 等待一个特定的线程退出         |
| pthread_yield        | 释放CPU来运行另外一个线程      |
| pthread_attr_init    | 创建并初始化一个线程的属性结构 |
| pthread_attr_destory | 删除一个线程的属性结构         |

## 线程实现

**在用户空间实现线程**：

内核并不知道线程的存在，以进程为单位分配CPU时间片，每个进程要有专用的线程表。

优点：允许每个进程有自己定制的调度算法、调度效率比内核调用高（无需陷入内核，即上下文切换，无需刷新内存高速缓存）

缺点：会因为阻塞调用/缺页中断阻塞整个进程直到完成

![2021091022161255313.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/2021091022161255313.png)

**在内核空间实现线程**

内核中会有用来记录系统中所有线程的线程表，当进行系统调度的时候，会通过对线程表的更新进行调度。**线程表拥有每个线程的寄存器、状态和其他信息。**

优点：不会因某个线程阻塞而导致进程阻塞

缺点：系统调用代价大，上下文切换开销大，以及需要切换系统状态

![2021091022161302314.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/2021091022161302314.png)

**混合实现**：将用户级线程与某些或者全部内核线程多路复用起来。编程人员可以自由控制用户线程和内核线程的数量，具有很大的灵活度。**内核只识别内核级线程，并对其进行调度。其中一些内核级线程会被多个用户级线程多路复用。**

![2021091022161351915.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/2021091022161351915.png)



# 存储器管理

## 存储器层次结构

存储层次至少具有三级：最高层为CPU寄存器，中间为主存，最底层是辅存。

![2021091022211932317 (2)](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/2021091022211932317.png)



## 程序的装入和链接

**程序装入方式**：

- **绝对装入方式**：绝对装入程序按照装入模块的地址，将程序和数据装入内存。

- **可重定位方式**：在采用可重定位装入程序将装入模块装入内存后，会使装入模块中的所有逻辑地址与实际装入内存的物理地址不同。

- **动态运行时装入方式**：装入内存后的所有地址都仍然是相对地址，而将相对地址转换为绝对地址是在程序真正执行的时候。

**程序链接方式**：

- ![img](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/ouFH3D.png)





## 内存管理



### 内存分配方式

**单一连续分配**：将内存分为系统区、用户区，将系统区的内存交给操作系统使用，而用户区内存分配给用户使用。

**固定分区分配**：内存空间被划分为若干个固定大小的区域，每个分区提供给某个进程使用。

**动态分区分配**：根据进程实际需要，结合数据结构动态分配内存。

- **位图**：由位图标记相关分区是否被使用

![2021091022170347411.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/2021091022170347411.png)

- **空闲链表**：由双向链表将空闲区域作为节点相连

### 相关分配算法

1. 首次适应算法：从头部顺序查找，分配内存使用。
2. 最佳适应算法：空闲区链表按照容量大小排序，遍历空闲区链表找到最佳空闲区，分配内存使用。
3. 快速适应算法：拥有多个空闲区链表，每个空闲区链表存储一种容量的空闲区，快速找到合适的内存分配使用。

### 内存回收过程

- 回收区和一块空闲区相邻，且回收区在空闲区下边：将回收区包含进空闲区
- 回收区和一块空闲区相邻，且空闲区在回收区下边：将回收区和空闲区合并，新的空闲区采用回收区的地址

- 回收区在两块空闲区中间：将三个区域合并，新的空闲区使用顶部的空闲区地址
- 单独的回收区：转为空闲区插入空闲区链表

### 内存存储管理

**页式存储管理**：将进程逻辑空间等分为若干个页面，物理内存空间分为若干个物理块，以页面为单位将进程装入物理块。**由页表记录进程逻辑空间与物理空间的映射**

![on1nDf.md.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/on1nDf.md.png)

- 缺点：由于页面大小的原因，会导致碎片多，单一的页式存储也会导致页表占用内存空间大。
- 优点：符合计算机的存储管理要求
- 解决方案：采用多级页表，防止一次页表的页表项过大

**段式存储管理**：将进程逻辑空间划分为若干段（非等分），**由段表记录逻辑空间到物理空间的映射**。

- 优点：适合用户需求，满足程序的共享

![on1QUg.md.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/on1QUg.md.png)

**段页式存储管理**：结合了提高内存利用率的分页管理、满足用户需求的分段，将进程先分为段，再分为页。

### 页面置换算法

当发生缺页异常的时候，需要相关的页面置换算法。

**最优页面置换算法**：将不再需要或者很久以后才需要的页面置换出去，这是一种理想的置换算法。

**先进先出页面置换算法**：由操作系统维护一个所有在当前内存中的页面的链表，缺页时移除头部的页，并且把新的页添加到表尾。

**最近最少使用页面置换算法**：在缺页中断时，置换未使用时间最长的页面。

## 虚拟地址空间

将物理内存地址暴露给进程的缺点：

- 用户程序可以寻址内存中的字节，容易破坏操作系统
- 多个用户程序容易发生冲突，并发困难

**虚拟地址空间**：创建了一种抽象内存供程序使用。地址空间是进程可以用来寻址内存的地址集。每个进程都有它自己的地址空间，独立于其他进程的地址空间。

在没有虚拟内存的计算机上，系统直接将虚拟地址送到内存中线上，读写操作都使用同样地址的物理内存。**在使用虚拟地址空间技术时，虚拟地址不会直接发送到内存总线上**。相反，会使用 `MMU内存管理单元`把**虚拟地址映射为物理内存地址**。

**基址寄存器和变址寄存器**：采用了虚拟地址空间后，要实际定位到程序的物理内存地址，采用**动态重定位方法，使用CPU中的基址寄存器、变址寄存器**来对地址空间转换为物理内存地址。

- 基址寄存器：存储数据内存的起始位置
- 变址寄存器：存储应用程序的长度。

![202109102218283221.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102218283221.png)

------

虚拟地址空间由固定大小的单元组成，这种固定大小的单元称为 `页(pages)`。而相对的，物理内存中也有固定大小的物理单元，称为 `页框(page frames)`。

在没有虚拟内存的计算机上，系统直接将虚拟地址送到内存中线上，读写操作都使用同样地址的物理内存。**在使用虚拟内存时，虚拟地址不会直接发送到内存总线上**。相反，会使用 `MMU(Memory Management Unit)` 内存管理单元把**虚拟地址映射为物理内存地址**。

![202109102218290092.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102218290092.png)

映射关系由页表进行管理，如果MMU 注意到该页面没有被映射，于是 CPU 会`陷入(trap)`到操作系统中。这个陷入称为 `缺页中断(page fault)` 或者是 `缺页错误`。操作系统会选择一个很少使用的页并把它的内容写入磁盘。

针对虚拟地址到物理地址映射速度优化主要有：TLB（转换检测缓冲区）位于MMU里面。

### 页表

虚拟页号可作为页表的索引用来找到虚拟页中的内容。由页表项可以找到页框号（如果有的话）。然后把页框号拼接到偏移量的高位端，以替换掉虚拟页号，形成物理地址。

![202109102218316234.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102218316234.png)

### **页表项结构**

![202109102218331946.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102218331946.png)

页框号：实际物理地址

在/不在位：1为该页表项有效，0为无效，即缺页异常

修改位/访问位：跟踪页面使用情况

高速缓存禁止位：决定了映射到寄存器还是存储器

### TLB

TLB是一个内存管理单元用于改进虚拟地址到物理地址转换速度的缓存。

TLB是位于内存中的**页表的cache**，如果没有TLB，则每次取数据都需要两次访问内存,即查页表获得物理地址和取数据.

![2021091022183553010.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/2021091022183553010.png)

## 虚拟内存

**交换技术**：针对于内存不足以程序运行的情况，有两种方式，第一种是**交换**，将进程放入内存中执行后，再把它放回磁盘。故空闲进程会存放在磁盘中。第二种是**虚拟内存**。

虚拟存储器，是指具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器系统。

具有多次性、对换性和虚拟性三大主要特征。

- 多次性：多次性是指一个作业被分成多次调入内存运行
- 对换性：对换性是指允许在作业的运行过程中进行换进、换出

- 虚拟性：虚拟性是指能够从逻辑上扩充内存容量

虚拟内存主要由虚拟存储器实现，具体内存管理也大体一样，分为：请求分页、请求分段、请求段页式，

**相关置换算法**：

- 先进先出算法(FIFO)
- 最不经常使用算法(LFU)
- 最近最少使用算法(LRU)

# 处理器管理

CPU 主要和内存进行交互，从内存中提取指令并执行它。一个 CPU 的执行周期是从内存中提取第一条指令、解码并决定它的类型和操作数，执行，然后再提取、解码执行后续的指令。重复该循环直到程序运行完毕。

除了用于保存变量和临时结果的通用寄存器外，还有以下寄存器。

- `程序计数器(program counter)`：指示下一条需要从内存提取指令的地址。提取指令后，程序计数器将更新为下一条需要提取的地址。
-  `堆栈指针(stack pointer)`：它指向内存中当前栈的顶端。堆栈指针会包含输入过程中的有关参数、局部变量以及没有保存在寄存器中的临时变量。
-  ` 程序状态字寄存器PSW(Program Status Word)`：维护的8个字节(64位) long 类型的数据集合。跟踪当前系统状态。除非发生系统结束，否则我们可以忽略 PSW 。用户程序通常可以读取整个PSW，但通常只能写入其某些字段。PSW 在系统调用和 I / O 中起着重要作用。

![](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102217148395.png)

# 文件系统

文件系统存储在`磁盘`中。大部分的磁盘能够划分出一到多个分区，叫做`磁盘分区`。每个分区都有独立的文件系统，每块分区的文件系统可以不同。磁盘的 0 号分区称为 `主引导记录(MBR)`，用来`引导(boot)` 计算机。在 MBR 的结尾是`分区表(partition table)`。

当计算机开始引 boot 时，BIOS 读入并执行 MBR。

**引导块**

MBR 做的第一件事就是`确定活动分区`，` 读入引导块(boot block)` 并执行。引导块中的程序将加载分区中的操作系统。为了一致性，每个分区都会从引导块开始，即使引导块不包含操作系统。引导块占据文件系统的前 4096 个字节，从磁盘上的字节偏移量 0 开始。引导块可用于启动操作系统。

![202109102219299172.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102219299172.png)

**超级块**

超级块 的大小为 4096 字节，从磁盘上的字节偏移 4096 开始。超级块包含文件系统的所有关键参数

- 文件系统的大小
- 文件系统中的数据块数
- 指示文件系统状态的标志
- 分配组大小

在计算机启动或者文件系统首次使用时，超级块会被读入内存。

**空闲空间块**

用位图或者链表管理空闲块。

**inode**

在读写文件之前，先打开文件，检查其访问权限。若权限许可，系统将返回一个小整数，称作`文件描述符(file descriptor)`，供后续操作使用。若禁止访问，系统则返回一个错误码。

索引节点。它是一个数组的结构，每个文件有一个 inode，inode 非常重要，它说明了文件的方方面面。

- 模式/权限（保护）
- 所有者 ID
- 组 ID
- 文件大小
- 文件的硬链接数
- 上次访问时间
- 最后修改时间
- inode 上次修改时间

文件分为两部分，索引节点和块。一旦创建后，每种类型的块数是固定的。

## 文件的实现

**连续分配**：按照连续数据块进行分配。

- 优点：实现简单、高性能
- 缺点：碎片问题

**链表分配**：按照链表方式分配数据块，节点的是磁盘指针

- 优点：充分利用数据块
- 缺点：不支持随机访问，IO代价大

**inode**：给每个文件赋予一个称为 `inode(索引节点)` 的数据结构，每个文件都与一个 `inode` 进行关联，inode 由整数进行标识。只有在文件打开时，其 inode 才会在内存中。

```
* 文件的字节数

　　* 文件拥有者的User ID

　　* 文件的Group ID

　　* 文件的读、写、执行权限

　　* 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。

　　* 链接数，即有多少文件名指向这个inode

　　* 文件数据block的位置

```



## 目录的实现

目录项提供了查找文件磁盘块所需要的信息。目录系统的主要功能就是 **将文件的 ASCII 码的名称映射到定位数据所需的信息上**。

![2021091022194451917.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/2021091022194451917.png)

对于采用 inode 的系统，每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。

## 共享文件

**硬链接**：多个文件名指向同一个inode号码。【inode链接数会发生变化】

```shell
ln 源文件 目标文件
```

**软链接**：文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。

```shell
ln -s 源文文件或目录 目标文件或目录
```

**磁盘调度算法**：

- 先来先服务：磁盘臂按照FIFO原则移动
- 最短路径优先：磁盘臂按照最短路径优先原则移动
- 电梯算法：磁盘臂向一端移动后回来

## 提升性能

- **高速缓存**：块高速缓存、缓冲区高速缓存
- **块提前读**：提前预读下一个块【针对顺序读取的文件】
- **减少磁盘臂运动**：把有可能顺序访问的块放在一起，当然最好是在同一个柱面上，从而减少磁盘臂的移动次数

# I/O 管理

I/O 分为两种：物理I/O 和 `逻辑I/O(Logical I/O)`。

物理 I/O 通常是从磁盘等存储设备实际获取数据。逻辑 I/O 是对存储器（块，缓冲区）获取数据。

大部分`物理IO(physical I/O)` 是异步的。CPU 传输完成后会转而做其他事情，等到中断发生后，CPU 才会回到传输这件事情上来。

| 比较条件     | 同步传输                       | 异步传输                                   |
| ------------ | ------------------------------ | ------------------------------------------ |
| 概念         | 块头序列开始                   | 它分别在字符前面和后面使用开始位和停止位。 |
| 传输方式     | 以块或帧的形式发送数据         | 发送字节或者字符                           |
| 同步方式     | 同步时钟                       | 无                                         |
| 传输速率     | 同步传输比较快                 | 异步传输比较慢                             |
| 时间间隔     | 同步传输通常是恒定时间         | 异步传输时间随机                           |
| 开销         | 同步开销比较昂贵               | 异步传输开销比较小                         |
| 是否存在间隙 | 不存在                         | 存在                                       |
| 实现         | 硬件和软件                     | 只有硬件                                   |
| 示例         | 聊天室，视频会议，电话对话等。 | 信件，电子邮件，论坛                       |

### 缓冲

通常情况下，从一个设备发出的数据不会直接到达最后的设备。其间会经过一系列的校验、检查、缓冲等操作才能到达。**优点：先到达缓冲区，从而消除缓冲区填满速率和缓冲区过载。**

### 共享和独占

有些 I/O 设备能够被许多用户共同使用，但是某些设备必须具有独占性，即只允许单个用户使用完成后才能让其他用户使用。

此时采用**SPOOLing技术（假脱机技术）**将物理设备虚拟为多个逻辑设备，在队列中调用设备，从而实现共享。

一共有三种控制 I/O 设备的方法

- 使用程序控制 I/O
- 使用中断驱动 I/O
- 使用 DMA 驱动 I/O

## 使用程序控制 I/O

使用程序控制 I/O 又被称为 `可编程I/O`，它是指由 CPU 在驱动程序软件控制下启动的数据传输，来访问设备上的寄存器或者其他存储器。CPU 会发出命令，然后等待 I/O 操作的完成。由于 CPU 的速度比 I/O 模块的速度快很多，因此可编程 I/O 的问题在于，CPU 必须等待很长时间才能等到处理结果。CPU 在等待时会采用`轮询(polling)`或者 `忙等(busy waiting)` 的方式，结果，整个系统的性能被严重拉低。

1. CPU 请求 I/O 操作
2. I/O 模块执行响应
3. I/O 模块设置状态位
4. CPU 会定期检查状态位
5. I/O 不会直接通知 CPU 操作完成
6. I/O 也不会中断 CPU
7. CPU 可能会等待或在随后的过程中返回

## 使用中断驱动 I/O

在 CPU 等待 I/O 设备的同时，能够做其他事情，等到 I/O 设备完成后，它就会产生一个中断，这个中断会停止当前进程并保存当前的状态。

1. CPU 进行读取操作
2. I/O 设备从外围设备获取数据，同时 CPU 执行其他操作
3. I/O 设备中断通知 CPU
4. CPU 请求数据
5. I/O 模块传输数据

## 使用DMA的 I/O

DMA即直接内存访问，它意味着 CPU 授予 I/O 模块权限在不涉及 CPU 的情况下读取或写入内存。即 IO 过程不需要 CPU 的参与。由于 DMA 设备可以直接在内存之间传输数据，而不是使用 CPU 作为中介，因此可以缓解总线上的拥塞。DMA 通过允许 CPU 执行任务，同时 DMA 系统通过系统和内存总线传输数据来提高系统并发性。

![2021091022255350115.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/2021091022255350115.png)

## 中断处理程序

![2021091022325732633.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/2021091022325732633.png)

中断处理程序步骤：

1. 保存所有没有被中断硬件保存的寄存器
2. 为中断服务程序设置上下文环境，可能包括设置 `TLB`、`MMU` 和页表
3. 为中断服务程序设置栈
4. 对中断控制器作出响应，如果不存在集中的中断控制器，则继续响应中断
5. 把寄存器从保存它的地方拷贝到进程表中
6. 运行中断服务程序，它会从发出中断的设备控制器的寄存器中提取信息
7. 操作系统会选择一个合适的进程来运行。如果中断造成了一些优先级更高的进程变为就绪态，则选择运行这些优先级高的进程
8. 为进程设置 MMU 上下文，可能也会需要 TLB，根据实际情况决定
9. 加载进程的寄存器，包括 PSW 寄存器
10. 开始运行新的进程

## 设备驱动程序

操作系统通常会将驱动程序归为 `字符设备` 和 `块设备`

![202109102225037209](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102225037209.png)

提供 I/O 设备到设备控制器转换的过程的代码称为 `设备驱动程序(Device driver)`

![202109102225030468.png](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/202109102225030468.png)

设备驱动程序接受到读写请求后，会检查当前设备是否在使用，如果设备在使用，请求被排入队列中，等待后续的处理。如果此时设备是空闲的，驱动程序会检查硬件以了解请求是否能够被处理。在传输开始前，会启动设备。等待设备就绪完成，再进行实际的控制。**控制设备就是对设备发出指令**。

设备控制器的主要主责是**控制一个或多个 I/O 设备，以实现 I/O 设备和计算机之间的数据交换**。

设备控制器接收从 CPU 发送过来的指令，继而达到控制硬件的目的。

## I/O 读写模式

- 无论是Socket的读写还是文件的读写，在Java层面应用开发或者Linux系统底层开发，都属于IO读写
- IO读写两大系统调用：read & write，两者都不负责内核缓冲区和磁盘之间的交换，底层的读写交换由**操作系统kernel**内核负责完成
- **read**：将数据从内核缓存区复制到进程缓存区
- **write**：将数据从进程缓存区复制到内核缓存区
- 在linux系统中，系统内核也有个缓冲区叫做内核缓冲区。每个进程有自己独立的缓冲区，叫做进程缓冲区。

![在这里插入图片描述](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/20190105163657587.png)

阻塞IO：指的是需要内核IO操作彻底完成后，才返回到用户空间，执行用户的操作。传统的IO模型都是同步阻塞IO。在java中，默认创建的socket都是阻塞的。

非阻塞IO：指的是用户程序不需要等待内核IO操作完成后，内核立即返回给用户一个状态值，用户空间无需等到内核的IO操作彻底完成，可以立即返回用户空间，执行用户的操作，处于非阻塞的状态。

同步IO：**同步与异步区别是一种用户空间与内核空间的调用发起方式。**同步IO是指用户空间线程是主动发起IO请求的一方，内核空间是被动接受方。

异步IO：是指内核kernel是主动发起IO请求的一方，用户线程是被动接受方。



### 1、同步阻塞IO

![在这里插入图片描述](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/20190105163801795.jpg)

- 优点：在阻塞等待期间，用户线程挂起，CPU资源空闲
- 缺点：高并发情况下需要大量的线程来维护连接，并且线程切换开销大

### 2、**同步非阻塞NIO**

![在这里插入图片描述](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/20190105163821398.jpg)

- 优点：发起IO的时候，用户线程不会阻塞，实时性较好
- 缺点：需要不断重复发起IO调用，不断轮询内核消耗大量的CPU时间片，利用率较低，不适用于高并发场景
- **Java中的NIO（New IO）并不是这种**，而是叫做多路复用IO

### 3、**IO多路复用模型**

![在这里插入图片描述](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/20190105163846560.jpg)

- IO多路复用模型：通过一种新的系统调用，一个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是内核缓冲区可读/可写），内核kernel能够通知程序进行相应的IO系统调用。
- 支持IO多路复用的系统调用，有 select、poll、epoll等，将目标提前注册到select/epoll的socket查询列表中，再开启整个模型的读流程。
- 优点：利用一条线程同时监测多个文件描述符，大大减小了系统的开销。
- 缺点：本质上，select/epoll系统调用，属于同步IO，也是阻塞IO。都需要在读写事件就绪后，自己负责进行读写，也就是说这个读写过程是阻塞的。

### 4、异步IO

![在这里插入图片描述](https://isbut-blog.oss-cn-shenzhen.aliyuncs.com/markdown-img/20190105163914730.jpg)

- 在内核kernel的等待数据和复制数据的两个阶段，用户线程都不是block(阻塞)的。用户线程需要接受kernel的IO操作完成的事件，或者说注册IO操作完成的回调函数，到操作系统的内核。所以说，异步IO有的时候，也叫做信号驱动 IO 。

### 5、select、poll、epoll

- **select**
  1. select 有最大文件描述符限制
  2. 为了获取具体哪个文件描述符有事件可用，select 需要对所有监听的文件描述符进行线性扫描
  3. 每次调用 select ，操作系统都需把文件描述符集合在内核和用户空间中相互拷贝
- **poll**
  1. poll **`基于链表来存储的`**，没有最大文件描述符限制
  2. 为了获取哪个文件描述符，poll 也需要对监听的文件描述符进行线性扫描，`特点是水平触发`

- **epoll**

  1. epoll 有两种执行模式，一种是水平触发（level-triggered），一种是边缘触发（edge-triggered），默认是水平触发。
  2. `没有最大并发连接的限制`，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。
  3. `效率提升，不是轮询的方式，不会随着FD数目的增加效率下降`。只有活跃可用的FD才会调用callback函数；`即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关`，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。
  4. `内存拷贝`，利用mmap()文件映射内存加速与内核空间的消息传递；`即epoll使用mmap减少复制开销`。
  5. **水平触发：**level-triggered 是一个文件描述符就绪了，也就是有事件准备读或准备写，调用 epoll 之后内核会把这个文件描述符从内核拷贝到用户空间，并通知用户对应的事件，如果用户此时选择不处理该描述符的事件，即用户不进行数据读或不进行数据写，下次调用 epoll 时，内核依然会返回这个事件。![img](https://sanyuesha.com/python-server-tutorial/book/imgs/level-triggered.jpg)
  6. **边缘触发：**edge-triggered 是如何一个文件描述符就绪了，也就是有事件准备读或准备写，调用 epoll 之后内核会把这个文件描述符从内核拷贝到用户空间，并通知用户对应的事件，如果用户选择不处理该描述符的事件，即用户不进行数据读或不进行数据写，下次调用 epoll 时，内核不会再返回这个事件，除非把对应的事件重新激活，内核才会在下次调用中返回该事件。![img](https://sanyuesha.com/python-server-tutorial/book/imgs/edge-triggered.jpg)

  4. evel-triggered 模式是尽可能的让事件被用户应用程序感知到，而 edge-triggered 可能的问题是也许会会让用户应用程序错过某些事件，因为它只在事件发生的那一刻才会通知用户。edge-triggered 更高效，但是 level-triggered 更可靠。
